{"Error-Handling-in-GitHub-Workflow-Extensions":{"title":"Error Handling in GitHub Workflow Extensions","links":[],"tags":["PluginExtension","ProgrammingTools","ErrorHandling","GitHubWorkflow","SoftwareDevelopment","post/medium","Git","Obsidian"],"content":"I recently created my first community plugin for Obsidian, which has basic functions for practicing pronunciation. After submitting it, I received feedback from a reviewer suggesting I change the plugin’s name because its features are more focused on the pronunciation of selected text.\nFollowing the advice, I updated the information in manifest.json, README, and the repository name. After making these changes, I submitted my pull request (PR) again but encountered an error:\nError: fatal: couldn&#039;t find remote ref refs/pull/4172/merge\nThe process &#039;/usr/bin/git&#039; failed with exit code 128\n\nI believe the error was caused by the repository name change. Even though I updated everything, the workflow still referenced the same old information:\nRepo info: goberomsu/british-pronunciation-plugin\nFound issue: Your repository does not have issues enabled. Users will not be able to report bugs and request features.\n\nFortunately, I realized what was wrong and fixed it!\nHow to Solve This Issue\nIf you’re facing a similar issue, as discussed in this forum post, here’s a simple solution:\n\nDelete the Obsidian release fork: Remove the forked repository from your GitHub account.\nFork the release again: Fork the original repository once more to your account.\nCreate a new Pull Request (PR): After making your changes, open a new PR to submit your code.\n\nThis process resets the fork, allowing you to avoid the “couldn’t find remote ref” error during validation."},"Solution-for-Nginx-SSL-Certificate-Passphrase-Issue":{"title":"Solution for Nginx SSL Certificate Passphrase Issue","links":[],"tags":["post/medium"],"content":"Solution for Nginx SSL Certificate Passphrase Issue\nEnsuring the seamless operation of your Nginx server, especially in automated environments like Docker, is crucial. This guide walks you through diagnosing and resolving the issue where Nginx fails to load an SSL certificate due to an encrypted key file requiring a passphrase.\nProblem Diagnosis\nLog Analysis\nReviewing the Nginx error logs reveals the following message:\nnginx: [emerg] cannot load certificate key &quot;/etc/ssl/certs/wildcard_eduroam_kr.key&quot;: PEM_read_bio_PrivateKey() failed\n(SSL: error:1400006B:UI routines::processing error:while reading strings error:0480006D:PEM routines::problems getting password\nerror:07880109:common libcrypto routines::interrupted or cancelled error:07880109:common libcrypto routines::interrupted or\ncancelled error:04800068:PEM routines::bad password read)\nThis error indicates that the wildcard_eduroam_kr.key file is encrypted and requires a passphrase, which Nginx cannot automatically provide during startup.\nRemoving the Passphrase From the Key File\nWhy Remove the Passphrase?\nFor automated environments such as Docker, manual passphrase entry during server startup is impractical. Removing the passphrase ensures Nginx can automatically load the SSL key, facilitating seamless automated deployments and operations.\nSteps to Remove the Passphrase\n\n\nExecute OpenSSL Command\nUse the openssl rsa command to create a new key file without the passphrase:\nopenssl rsa -in wildcard_eduroam_kr.key -out wildcard_eduroam_kr.key.no_pass\n\n\nEnter Passphrase\nWhen prompted, enter the current passphrase for the key file:\nEnter pass phrase for wildcard_eduroam_kr.key:\nThis will generate a new key file without a passphrase.\n\n\nVerify the New Key File\nEnsure the new key file has been created successfully:\nls -l wildcard_eduroam_kr.key.no_pass\nAnd, replace wildcard_eduroam_kr.key!\n\n\nModifying Docker Compose Configuration\nUpdating the docker-compose.yml File\nModify your docker-compose.yml to use the new key file without a passphrase:\nnginx:\n  logging:\n    driver: &quot;json-file&quot;\n    options:\n      max-size: &quot;50m&quot;\n  environment:\n    - TZ=Asia/Seoul\n  image: nginx:latest\n  container_name: nginx\n  volumes:\n    - ./nginx/nginx.conf:/etc/nginx/nginx.conf\n    - ./nginx/certs/cert_wildcard.eduroam.kr.crt:/etc/ssl/certs/cert_wildcard.eduroam.kr.crt\n    - ./nginx/certs/wildcard_eduroam_kr.key:/etc/ssl/certs/wildcard_eduroam_kr.key\n  deploy:\n    restart_policy:\n      condition: unless-stopped\n  ports:\n    - 443:443\n  networks:\n    - public\n    - private\nRebuilding and Restarting Docker Containers\nRebuild Docker Image and Restart Containers\nReflect the changes by rebuilding the Docker image and restarting the containers:\ndocker compose down\ndocker compose build\ndocker compose up -d\nRebuilding ensures that the new, unencrypted key file is used, as the key files are typically excluded from version control for security reasons and must be explicitly included in the build process.\nVerifying the Resolution\nCheck Nginx Container Logs\nConfirm that the issue is resolved by inspecting the Nginx container logs:\ndocker-compose logs nginx\nValidate Successful Startup\nEnsure the Docker container is running correctly:\ndocker ps\n\nFinally, verify that there are no errors related to certificate loading in the logs:\ndocker logs [nginx-container-ID]\n"},"Terminology-generating-workflow-with-Obsidian-and-Generative-AI":{"title":"Terminology generating workflow with Obsidian and Generative AI","links":["Perplexity","Obsidian-Plugin---Templater","Gemini","T03---Research-Terminology","2024-08-06","@구요한"],"tags":["post/medium"],"content":"General Terminology\n\nPerplexity + Obsidian Plugin - Templater\n\nwhen we learn new fields, we need to know the terminology. There is way to make terminology easier with obsidian avoiding halluciations\nFirst, find terminology by using an AI search tool like Perplexity. Then, copy the result and paste to generative AI such as Gemini and chatGPT using template\nPerplexity gives you result based on reference and chatGPT change your appropriate template.\nResearch Terminology\n\nT03 - Research Terminology\n\nShare Obsidian &amp;&amp; AI workflow\nThis is way to make a terminology for research!\nFirst, search for the terminology using consensus gpts,an AI-powered research tool.\nThen, copy the result and paste it into a template for chatGPT\nconsensus provides you result based on academic article,helping you avoid halluciations.\nchatGPT will generate you terminology note :)\nThinking\n\n2024-08-06 21:38 Reference : @구요한\n2024-08-06 21:50 easier 잘 못스네\n"},"Zotero-7-hookmark-동작-안하는-것-해결-방법":{"title":"Zotero 7 hookmark 동작 안하는 것 해결 방법","links":["조테로-(Zotero)","Hookmark"],"tags":["zotero","post/medium"],"content":"I’m currently using Zotero for my research, Zotero is free and easy to use.\nThis week, I upgraded to Zotero 7 beta because it has a better design than the previous version. However, when I launched the new Zotero and tried to use Hookmark to connect the Obsidian vault with Zotero, Hookmark was not working.\nToday, I will share how I solved this problem\nZotxt Extension\nGo to the zotxt GitHub page. Download Zotxt suitable for your version of Zotero. Install zotxt by following the instructions on the its GitHub page.\nZotxt is a Zotero extension for supporting utilities that deal with plain text files (e.g., markdown, reStructuredText, latex, etc.) This plugin will be used for Hookmark required text to make hookmark link\nZotero-markdown-translator\nGo to the silentdot/zotero-markdown-translator GitHub page. download the Zotero translator from the repository. Then install the translator by following the instructions provided on the Github page.\nThe Zotero Markdown Translator plugin creates Markdown links when exporting. To solve my problem, I needed to change the Item Format to Markdown Item URI\n\nGo to the Export tab.\nSet the Item Format to Markdown Item URI.\nThis ensures that your exported items are in the correct format for Markdown.\n\nConclusion\n\nFinally, reboot Zotero and check if the problem is solved. If you need further information,The latest discussions around Zotero 7 beta and its compatibility with Hookmark can be found here. It includes updates on potential issues and fixes related to Hookmark."},"index":{"title":"Home","links":["아버지를-존경할-이유"],"tags":[],"content":"CV/포토폴리오 겸으로 사용할 장소입니다, Top-down 형식으로 전개해 나갈 예정입니다\n\n아버지를 존경할 이유\n\nReference\n\nMinwoo Seong | phd hci @ GIST\nWelcome to Quartz 4\n개발자 유니의 두 번째 뇌\ndoors - 서울외계인의 지식정원 - Obsidian Publish\n"},"검색-엔진-Obsidian-plugin-Omnisearch-연동하기":{"title":"검색 엔진 Obsidian plugin Omnisearch 연동하기","links":[],"tags":["Omnisearch","검색엔진","Obsidian","Browser","연결","article","post/tistory"],"content":"검색엔진 Obsidian Plugin Omnisearch 연동하기\nOmnisearch는 Obsidian의 강력한 검색 플러그인으로, 다음과 같은 특징을 가지고 있습니다:\n\n다양한 파일 형식 지원: 노트, Office 문서, PDF, 이미지 등을 빠르게 검색\n오타 저항성: 검색어의 오타에도 관련 결과를 찾아냄\n필터링 기능: 다양한 파일 형식별 필터링 가능\n키보드 중심 워크플로우: 효율적인 검색 및 탐색 지원\n외부 접근성: 로컬 HTTP 서버를 통해 Obsidian 외부에서도 쿼리 가능\n\nOmnisearch를 브라우저와 연동하면 다음과 같은 이점을 얻을 수 있습니다:\n\n통합 검색 경험: 웹 검색과 개인 노트 검색을 동시에 수행\n지식 연결: 외부 정보와 개인 지식을 쉽게 연결\n맥락 이해 향상: 검색 결과의 맥락을 더욱 풍부하게 이해\n노트 활용도 증가: 개인 노트의 활용 빈도와 가치 상승\n시간 절약: 여러 플랫폼을 오가며 검색할 필요 없이 한 곳에서 모든 정보 접근\n아이디어 발견: 웹 정보와 개인 노트를 동시에 보며 새로운 연결점 발견 가능\n\n이 가이드에서는 Omnisearch를 브라우저와 연동하는 방법을 단계별로 안내하여, 사용자가 이러한 장점들을 최대한 활용할 수 있도록 돕습니다.\nOmnisearch를 Google/Kagi에 연결하는 방법\n\n\nOmnisearch의 최신 버전을 Obsidian에 설치하고, 설정에서 HTTP 서버를 활성화합니다.\n\n\n\n브라우저에 Tampermonkey (또는 다른 userscript 관리자)를 설치합니다.\n\n\n\n브라우저의 Developer Mode를 활성화합니다. 브라우저별 확장 프로그램 페이지 링크:\n\nChrome: chrome://extensions/\nArc: arc://extensions/\n\n각 브라우저에서 “개발자 모드” 또는 “Developer Mode” 토글을 찾아 활성화합니다. Chrome과 Arc는 오른쪽 상단, Edge는 왼쪽 하단에 있습니다.\n\n\n이 작업을 통해 Tampermonkey를 통해 userScripts API를 사용할 수 있게 됩니다.\n\n\n선호하는 검색 엔진에 해당하는 userscript를 설치합니다, extension을 설치하고 아래 링크에 접속하면 Tampermonkey가 접근 가능하도록 할 것이냐 물어봅니다\n\nKagi\nGoogle\nDuckDuckGo\nBing\n\n\n다음은 experimental Javascript feature를 실행시켜야 합니다\n\n\nExperimental JavaScript features를 활성화합니다. 브라우저별 설정 페이지 링크:\n\nChrome: chrome://flags/#enable-experimental-web-platform-features\nArc: arc://flags/#enable-experimental-web-platform-features\n\n각 브라우저에서 “Experimental Web Platform features”를 찾아 “Enabled”로 설정합니다.\n\n\n\n\n이제 처음 구글 search를 하면, 아래와 같이 권한을 요구합니다. 여기서 Allow를 누르시면 사용하실 수 있습니다\n\n궁금증\n왜 Developer Mode를 활성화해야 하나요?\nDeveloper Mode는 userscript의 두 단계 사용자 권한 부여를 위해 필요합니다: userScripts 권한과 Developer Mode 옵션입니다. userScripts 권한만으로는 설치 시 사용자 경고를 트리거하지 않습니다. 따라서 이 추가 단계는 사용자가 Userscripts를 사용하는 확장 프로그램을 실행하는 데 있어 신중한 결정을 내리도록 하기 위한 Google의 의도를 반영합니다.\nOmnisearch와 브라우저 연동의 동작 원리\n\n로컬 HTTP 서버: Omnisearch 플러그인은 Obsidian 내에서 로컬 HTTP 서버를 실행합니다. 이 서버는 외부 애플리케이션(이 경우 브라우저)에서 Obsidian 노트를 검색할 있게 해줍니다.\nUserscript: Tampermonkey를 통해 설치된 userscript는 브라우저의 검색 결과 페이지에 삽입됩니다. 이 스크립트는 사용자의 검색 쿼리를 감지합니다.\nAPI 요청: userscript는 감지한 검색 쿼리를 사용하여 Omnisearch의 로컬 HTTP 서버에 API 요청을 보냅니다.\n결과 처리: Omnisearch 서버는 요청을 처리하고, Obsidian 노트에서 관련된 결과를 찾아 반환합니다.\n결과 표시: userscript는 받은 결과를 처리하여 브라우저의 검색 결과 페이지에 Obsidian 노트의 검색 결과를 삽입합니다.\n"},"조테로-(Zotero)":{"title":"조테로 (Zotero)","links":["Zotero-7-hookmark-동작-안하는-것-해결-방법"],"tags":["논문관리","참고문헌관리","인용관리","학술연구","연구도구","ReferenceManagement","CitationManagement","AcademicResearch","BibliographyManagement","ResearchTools","terminology"],"content":"조테로 (Zotero)\nWhat is Zotero\n\n정의 (Definition):\n\n조테로는 연구자들이 소스를 관리하고 조직할 수 있게 도와주는 무료, 오픈 소스 참고문헌 관리 도구입니다. 사용자가 연구 자료를 수집, 정리, 인용, 공유할 수 있게 지원합니다(Center for History and New Media, 2022).\n이 도구는 연구논문 작성 시 필요한 인용문을 자동으로 생성해주고, 사용자의 라이브러리를 동기화하여 여러 장치에서 접근할 수 있게 합니다(Roy Rosenzweig Center for History and New Media, 2021).\n\n\n예시 (Examples):\n\n연구자가 논문을 작성하면서 조테로를 사용하여 참고문헌을 관리하고, 필요한 인용 스타일로 서식을 적용할 수 있습니다.\n학생이나 교수가 공동 연구 프로젝트에 참여할 때 조테로의 그룹 기능을 사용하여 자료를 공유하고 협업할 수 있습니다.\n\n\n\nPlugin\n\nMohamedElashri/awesome-zotero: A curated list of awesome Zotero resources\n\nZotero &amp;&amp; Hookmark\n\nZotero 7 hookmark 동작 안하는 것 해결 방법\n\nTranslate for Zotero\n\nwindingwind/zotero-pdf-translate: Translate PDF, EPub, webpage, metadata, annotations, notes to the target language. Support 20+ translate services.\n\nZotero is a research support tool. I recommend the Zotero plugin for translating academic articles. This plugin allows customization of settings such as auto-translation selection, auto-translation annotations, and views.\nAuto-translation selection: When a phrase is selected, it is automatically translated and the translated phrase is displayed in a pop-up.\nAuto-translation annotations: When annotations are made on a phrase, the plugin either adds the translated phrase or changes the annotations to their translated version.\nBy utilizing these features, researchers can streamline their workflow and improve the efficiency of their academic research process."},"크램폴린-IDE---NGINX-문제-해결":{"title":"크램폴린 IDE - NGINX 문제 해결","links":["🔥-Programmer","🏷️-Develop-Notes","Nginx","00.-Inbox/Notion/Campus-life/카카오-테크-캠퍼스/카카오-테크-캠퍼스","Projects/카카오테크캠퍼스/카카오-테크-캠퍼스","축팅","⚙️-Kubernetes"],"tags":["대외활동/카카오테크캠퍼스","개발/환경/에러","포스트","개발"],"content":"persona :: 🔥 Programmer\nindex :: 🏷️ Develop Notes\n#개발\n크램폴린 IDE - Nginx 문제 해결\n2023년은 카카오 테크 캠퍼스에서 교육을 받았습니다\n오늘은 카카오의 클라우드 기반 학습 관리 시스템인 크램폴린 환경에 배포하며 겪은 문제를 나누려고 합니다\nIntro. 무슨 일인가\n카카오 테크 캠퍼스 3단계 프로젝트의 주제는 축팅(네 컷 사진을 통해 축제에서 자연스러운 만남을 주선하는 서비스)이었습니다\n사진 업로드 기능을 배포 환경에서 테스트하니, Nginx 413 Request Entity Too Large 에러가 발생하였습니다\n찾아보니 기본 body size가 1M인 것을 해제하면 되는거라 금방 다시 배포를 하였습니다\n하지만,,, 문제는 해결 되지 않았죠\n\n\nNginx 413 에러란?\n\n의미 : 요청 엔티티의 크기가 너무 크다\n파일 용량이 너무 커서 디스크가 가득 차 사이트가 다운 되는 것을 방지하기 위해 설정되어있다\n\n\n\n\n원인 파악\n\n원인을 파악하기 위해서 크램폴린 배포 플로우를 다시 상기 할 필요가 있었습니다\n왜냐하면, 크램폴린 IDE에서 배포는 쿠버네티스 환경에서 진행 되기 때문입니다\nKargo를 사용하여 DKOS 클러스터에 애플리케이션을 배포하는 것을 보면 알 수 있죠\n\n\nKargo\n\n쿠버네티스 클러스터에 애플리케이션을 배포하는 도구\n지금은 Kubespray로 프로젝트 이름이 변경 되었다고 한다\n\n\n\n\n1. 쿠버네티스 환경에서 Nginx 설정이 잘못 되었는가?\n쿠버네티스 환경에서 Nginx 설정을 할 수 있는 경로는 2가지입니다\n\n인그레스 컨트롤러(ingress controller) 설정\n\nNGINX 인그레스 컨트롤러에서 어노테이션(annotation)을 통해 Nginx 설정을 적용\n\n\nNGINX 설정 커스터마이징:\n\nNGINX의 설정 파일인 nginx.conf를 직접 수정한 Pod을 생성\n\n\n\n인그레스 컨트롤러(ingress controller) 설정 조절\n쿠버네티스의 인그레스 컨트롤러는 외부 요청을 클러스터 내부 서비스로 라우팅하는 역할을 합니다.\n먼저 카카오 크램폴린에서 기본으로 제공하는 Nginx 를 사용하고, 기존의 제가 설정한 관련 Pod들을 제거하였습니다\n그 후 body size를 조정하였습니다\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: example-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/proxy-body-size: &quot;64m&quot;\nspec:\n  rules:\n  - http:\n      paths:\n      - path: /example-path\n        pathType: Prefix\n        backend:\n          service:\n            name: example-service\n            port:\n              number: 80\n하지만,, 여전히 문제는 해결 되지 않았습니다\n2. NGINX 설정 커스터마이징\nNGINX 설정을 직접 수정하는 경우, nginx.conf 파일을 수정하여 Pod에 적용할 수 있습니다\nhttp {\n    …\n \n    client_max_body_size 64M;\n \n    …\n}\nConfigMap으로 설정을 주입하고, 직접 Nginx 이미지 패키징 할 때 설정 파일을 넣어 봤지만 여전히 문제는 해결 되지 않았습니다\n2. 로그 확인 : Hint 발견\nNginx Pod을 띄우고, 1M 이하의 이미지는 받아지지만, 용량을 초과하는 경우에 Postman에 에러를 뱉고 있으니, 이미지 크기 제한 문제가 확실했습니다\nPod 로그를 확인해보니, 다른 API 엔드 포인트에 대한 요청은 로그로 남고 있는데 413 에러가 누락 되는 것을 확인하였습니다\nNginx Pod에 사용 된 이미지의 경우, 바디 사이즈만 조절 되었기 때문에 로그가 누락 될리가 없는데 수상했습니다\nNginx 기본 Docker 이미지를 사용했다면, Nginx 에러 로그가 기록 되어야 하기 때문입니다\n왜냐하면, Nginx 이미지의 기본 로그 레벨은 error이고, 413 에러는 기본 error 레벨에서 기록 되어야하기 때문이죠\n먼가 제가 구성한 인프라의 문제가 아닐거라는 의심이 들었습니다\n3. 로컬에서 동일한 환경 구성 후 테스트\n의심되는 이미지(바디 사이즈 조절 된 기본 Nginx 이미지)를 로컬에서 테스해보았습니다\n\n재현 방법\n\n기존의 NGINX 이미지 생성 후 로컬 BE 프로젝트에 연결\n80881로 NGINX 연결하고, Postman으로 큰 이미지 전송\nNGINX 통과 후 BE 프로젝트 예외 반환 확인!\n\n\n\n\n큰 이미지가 결국 Nginx 이미지를 통과했으니, 제가 만든 이미지의 문제가 아닌거죠\n해결\n결론적으로 쿠버네티스 환경 관리자 분께 문의 드렸습니다\n확인 결과 저희 서비스 앞 단의 크램폴린에서 설정한 Nginx 문제라 판단이 되었습니다\n\n그 결과 문제 해결!\n이미지 퀄리티가 중요한 서비스에서 1M가 제한은 치명적이었고,\n팀 내에서 제가 배포를 맡고 있었어서 제 파트 문제라 스트레스를 많이 받았습니다\n이미지 제한 문제 해결하며 개발 일정이 밀리기도 했구요\n그래도 해결하니까 매우 뿌듯했습니다\n\n깨달은 점\n\n인프라 등 당연한 것들도 합리적인 의심을 할 필요가 있다\n협업 상황에서는 문제 진행 상황 공유와 적절한 시기에 시니어에게 도움을 요청하자\n\n될 때까지 잡고 늘어지다 개발 일정 밀리는 것은 일을 잘한다 할 수 없다\n\n\n\n\n\n\n  \n  \n\nTMI\n그리고, 저희 팀 카카오 테크 캠퍼스 3단계 우수조로 뽑혔습니다 올 한해 제일 짜릿한 순간이었어요\n\n궁금했던 점\nproxy_body_size와 client_max_body_size의 차이\nclient_max_body_size와 proxy_body_size는 NGINX 설정에서 비슷한 역할을 하지만, 적용되는 컨텍스트(context)에 따라 다릅니다\n\n\nclient_max_body_size:\n\n이 설정은 클라이언트로부터 직접 받은 요청의 본문 크기를 제한합니다.\nNGINX가 직접적으로 클라이언트의 요청을 처리할 때 사용됩니다.\n예를 들어, 클라이언트가 서버에 파일을 업로드하는 경우, client_max_body_size는 업로드할 수 있는 파일의 최대 크기를 제한합니다.\n\n\n\nproxy_body_size (어노테이션: nginx.ingress.kubernetes.io/proxy-body-size):\n\n이 설정은 NGINX가 프록시 서버로 동작할 때, 업스트림 서버로 전송되는 요청 본문의 크기를 제한합니다.\n주로 인그레스 컨트롤러와 같이 NGINX가 프록시 역할을 하는 경우에 사용됩니다.\n예를 들어, 인그레스 컨트롤러를 통해 내부 서비스로 요청을 전달하는 경우, 이 설정은 프록시를 통해 전달되는 요청 본문의 최대 크기를 제한합니다.\n\n\n\n결론\n\n\n직접 운영하는 NGINX 서버의 경우\n\nclient_max_body_size를 nginx.conf 파일에서 설정합니다. 이는 NGINX가 클라이언트로부터 직접 요청을 받을 때 적용됩니다.\n\n\n\n쿠버네티스 인그레스 컨트롤러 사용 시\n\nnginx.ingress.kubernetes.io/proxy-body-size 어노테이션을 사용하여 proxy_body_size를 설정합니다.\n이는 인그레스 컨트롤러를 통해 들어오는 요청에 대해 적용됩니다.\n\n\n"},"아버지를-존경할-이유":{"title":"아버지를 존경할 이유","links":[],"tags":["Family","Ethics","Business"],"content":"아빠한테 전화해서 존경한다고 말씀드렸다\n아버지라 부르지는 않지만, 호칭에 상관 없이 암튼 존경한다\n왜냐면, 아버지이기 때문이다, 그 무거운 이름을 짊어진 것이 정말 멋진 것임을 점점 느낀다\n최근에 책을 통해 사기를 당하면, 비가역적인 손상을 입을 수 있고,\n그 처벌 또한 시원하게 할 수 없는 경우가 잦다는 것을 알게 되었다\n왜냐면, 우리의 도덕과 법이 완전히 일치하지 않기 때문이다\n그런데, 그런 위험을 이겨내고 살아남아서 우리 가족을 지켜내셨고, 삶을 포기하지 않으셨다\n또, 어렸을 때부터 귀에 못이 박히도록,\n슬리퍼 신지 말고, 옷과 머리는 단정히 깔끔하게 다녀야 한다\n진짜 매일 말씀하셨는데, 이젠 그 말이 이해가 된다.\n아무렴 그 반대의 것을 잔뜩 누리면서 살았지만야\n분명히 드레스 코드는 많은 것을 드러내는 지표로 사용 되기 때문에\n단정하고, 깔끔한 외관이 여러모로 도움이 될 상황이 많은거 같다. 전략적으로 사용 될 수 있다\n사업하시는 아빠 입장에서 드레스 코드가 내포하는 의미가 무엇인지 알고 있기 때문에 그러셨겠군 싶다\n항상 강조하시는 사람을 만나면 무조건 인사 잘해야 한다.\n처음 보면 안녕하세요, 그 날 여러번 마주치면 싱긋 웃으면서 목례를 하라했던 것도 이해가 된다\n이해가 되는 요즘이다, 단순한 문장 뒤에 숨은 복잡한 백그라운드가 있음을 느낀다\n기회가 되면, 그 이야기를 들어보고 싶다아"}}