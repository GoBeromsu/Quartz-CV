---
tags: [MSc, MachineLearning, DataAnalysis, Statistics, public]
aliases: []
date_created: 2024-10-13
link: 
up:
  - "[[COM6509 Machine Learning and Adaptive Intelligence]]"
Habitus:
  - "[[â—¦ Knowledge]]"
  - "[[â—¦ Economic]]"
persona:
  - "[[ğŸ”¥ Analysist]]"
---
## 1. ML Classifier for Cancer Detection

You have built an ML classifier that detects whether a tissue appearing in an image is cancerous or not. Consider the cancerous class as the positive class. The following confusion matrix shows the predicted results obtained in the validation set:

|                     | cancerous (predicted) | healthy (predicted) |
|---------------------|----------------------:|--------------------:|
| cancerous (actual)  |                    30 |                   5 |
| healthy (actual)    |                    15 |                 100 |

Compute the precision, recall and accuracy of your ML classifier.
- [[Confusion Matrix]]
	- [[Precision]]
	- [[Accuracy]]
	- [[Recall]]

### Solution

Based on the confusion matrix:
- True Positive (TP) = 30
- False Positive (FP) = 15
- False Negative (FN) = 5
- True Negative (TN) = 100

Calculated metrics:

1. $Precision = TP / (TP + FP) = 30 / (30 + 15) = 30 / 45 = 2/3$ â‰ˆ 0.6667 or about 66.67%

2. Recall = $TP / (TP + FN) = 30 / (30 + 5) = 30 / 35 = 6/7$ â‰ˆ 0.8571 or about 85.71%

3. Accuracy = $(TP + TN) / (TP + TN + FP + FN) = (30 + 100) / (30 + 100 + 15 + 5) = 130 / 150 = 13/15$ â‰ˆ 0.8667 or about 86.67%

## 2. Student Exam Scores Normalization and Standardization

(*) The table below shows the scores achieved by a group of students on an exam. Using this data, perform the following tasks on the Score feature:

(a). A normalisation in the range [0, 1].

(b). A normalisation in the range [-1, 1].

(c). A standardisation of the data.

| ID    | 1  | 2  | 3  | 4  | 5  | 6  | 7  | 8  | 9  | 10 | 11 | 12 | 13 | 14 | 15 | 16 | 17 | 18 | 19 | 20 |
|-------|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|----|
| Score | 42 | 47 | 59 | 27 | 84 | 49 | 72 | 43 | 73 | 59 | 58 | 82 | 50 | 79 | 89 | 75 | 70 | 59 | 67 | 35 |

- [[Normalization]]
- **[0, 1] ë²”ìœ„ë¡œ ì •ê·œí™”**í•  ë•Œ ì‚¬ìš©ë˜ëŠ” ê¸°ë³¸ ê³µì‹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
  $$x_{\text{norm}} = \frac{x - x_{\text{min}}}{x_{\text{max}} - x_{\text{min}}}$$

- **[-1, 1] ë²”ìœ„ë¡œ ì •ê·œí™”**í•  ë•ŒëŠ”, ìœ„ì˜ ê²°ê³¼ì— 2ë¥¼ ê³±í•˜ê³  1ì„ ë¹¼ì„œ ë‹¤ìŒê³¼ ê°™ì´ ë³€í˜•í•©ë‹ˆë‹¤:
  $$x_{\text{norm}} = 2 \cdot \frac{x - x_{\text{min}}}{x_{\text{max}} - x_{\text{min}}} - 1$$

ë”°ë¼ì„œ, (b)ë²ˆ ë¬¸ì œì—ì„œ ì‚¬ìš©í•œ ê³µì‹ë„ Min-Max Normalizationì˜ ì¼ì¢…ìœ¼ë¡œ, ë‹¨ìˆœíˆ ë³€í™˜ ë²”ìœ„ë¥¼ [-1, 1]ë¡œ ì„¤ì •í•œ ê²ƒì…ë‹ˆë‹¤.


### Solution

(a) Normalization in range [0, 1]:
   $x_{norm} = \frac{x - min}{max - min} = \frac{x - 27}{89 - 27}$

(b) Normalization in range [-1, 1]:
   $x_{norm} = 2 \cdot \frac{x - min}{max - min} - 1 = 2 \cdot \frac{x - 27}{89 - 27} - 1$

(c) Standardization of the data:
   $x_{std} = \frac{x - mean}{std} = \frac{x - 60.95}{16.97}$

Where:
- $x$ is the original score
- $min = 27$, $max = 89$
- $mean = 60.95$, $std = 16.97$

To apply these formulas, substitute each score for $x$ in the respective equation.
## 3. Bike Rental Prediction Model

(*) We designed a model for predicting the number of bike rentals (y) from two attributes, temperature (xâ‚) and humidity (xâ‚‚),

$$y = 500 \times x_1 + 300 \times x_2.$$

The model was trained **after normalising the training data (between [0,1])**. xâ‚ had values between âˆ’10 and 39 while xâ‚‚ had values between 20 and 100. At test time, the model is used to predict the bike rentals for a vector $\mathbf{x}^* = [25, 70]^\top$. What is the value of the prediction y?

- Feature
	- Already normalised
- ë°ì´í„° ê°’ë„ [[Normalization]] ë˜ì–´ì„œ ë“¤ì–´ê°€ì•¼ í•˜ëŠ”êµ¬ë‚˜!

### Solution

1. ë¨¼ì € ì…ë ¥ ë°ì´í„°ë¥¼ [0,1] ë²”ìœ„ë¡œ ì •ê·œí™”í•©ë‹ˆë‹¤:

   $x_{1_{norm}} = \frac{x_1 - x_{1_{min}}}{x_{1_{max}} - x_{1_{min}}} = \frac{25 - (-10)}{39 - (-10)} = \frac{35}{49}$

   $x_{2_{norm}} = \frac{x_2 - x_{2_{min}}}{x_{2_{max}} - x_{2_{min}}} = \frac{70 - 20}{100 - 20} = \frac{50}{80} = \frac{5}{8}$

2. ì •ê·œí™”ëœ ê°’ì„ ì˜ˆì¸¡ ëª¨ë¸ì— ì ìš©í•©ë‹ˆë‹¤:

   $y = 500 \times x_{1_{norm}} + 300 \times x_{2_{norm}}$

3. ìµœì¢… ì˜ˆì¸¡ê°’ ê³„ì‚°:

   $y = 500 \times \frac{35}{49} + 300 \times \frac{5}{8}$

ì´ ì‹ì„ ê³„ì‚°í•˜ë©´ ìµœì¢… ì˜ˆì¸¡ê°’ yë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
## 4. Outlier Removal Criterion

A simple criterion to remove outliers from a dataset is to compute the mean, Î¼, and the standard deviation, Ïƒ, of the variable of interest and consider values outside the range $(Î¼ - 3Ïƒ, Î¼ + 3Ïƒ)$ as outliers.

Applying this criterion to the Scores in Exercise 2, which ones of them can be considered as outliers?

### Solution

1. ë°ì´í„° ì¬í™•ì¸:
   42, 47, 59, 27, 84, 49, 72, 43, 73, 59, 58, 82, 50, 79, 89, 75, 70, 59, 67, 35

2. í‰ê· (Î¼) ê³„ì‚°:
   Î¼ = (42 + 47 + â€¦ + 67 + 35) / 20 = 1219 / 20 = 60.95

3. í‘œì¤€í¸ì°¨(Ïƒ) ê³„ì‚°:
   Ïƒ = âˆš[(Î£(x - Î¼)Â²) / N] â‰ˆ 16.97

4. ì´ìƒì¹˜ ë²”ìœ„ ê³„ì‚°:
   í•˜í•œ: Î¼ - 3Ïƒ = 60.95 - 3(16.97) = 10.04
   ìƒí•œ: Î¼ + 3Ïƒ = 60.95 + 3(16.97) = 111.86

5. ì´ìƒì¹˜ íŒë³„:
   1.04 < ì •ìƒ ë°ì´í„° < 111.86

ëª¨ë“  ì ìˆ˜ê°€ ì´ ë²”ìœ„ ë‚´ì— ìˆìœ¼ë¯€ë¡œ, ì´ ê¸°ì¤€ì— ë”°ë¥´ë©´ ì£¼ì–´ì§„ ë°ì´í„°ì…‹ì—ëŠ” ì´ìƒì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤.

ê°€ì¥ ë‚®ì€ ì ìˆ˜(27)ì™€ ê°€ì¥ ë†’ì€ ì ìˆ˜(89)ë„ ì´ ë²”ìœ„ ë‚´ì— ìˆì–´ ì´ìƒì¹˜ë¡œ ê°„ì£¼ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
## 5. Joint Probability Mass Function Analysis

(**) Suppose the joint probability mass function of two RVs X and Y is given as,

$$P(X = x, Y = y) = \begin{cases}
    1/3, & \text{if } (x = 0, y = 1), (x = 1, y = 0) \text{ or } (x = 2, y = 1) \\
    0,   & \text{otherwise}
\end{cases}$$

- [[Probability Independent]]
- [[Probability Correlation]]
#### (a). Are X and Y Independent?

1. ì£¼ë³€ í™•ë¥  ê³„ì‚°:
	 - P(X = 0) = 1/3, P(X = 1) = 1/3, P(X = 2) = 1/3
	 - P(Y = 0) = 1/3, P(Y = 1) = 2/3
2. ë…ë¦½ì„± ê²€ì¦:
	- ë§Œì•½ Xì™€ Yê°€ ë…ë¦½ì´ë¼ë©´, ëª¨ë“  xì™€ yì— ëŒ€í•´ $P(X = x, Y = y) = P(X = x) * P(Y = y)$ê°€ ì„±ë¦½í•´ì•¼ í•©ë‹ˆë‹¤.

$$
P(X = 0, Y = 1) = 1/3 â‰  P(X = 0) * P(Y = 1) = 1/3 * 2/3 = 2/9
$$
$$
P(X = 1, Y = 0) = 1/3 â‰  P(X = 1) * P(Y = 0) = 1/3 * 1/3 = 1/9
$$ $$
P(X = 2, Y = 1) = 1/3 â‰  P(X = 2) * P(Y = 1) = 1/3 * 2/3 = 2/9
$$
ë”°ë¼ì„œ Xì™€ YëŠ” ë…ë¦½ì´ ì•„ë‹™ë‹ˆë‹¤.

#### (b). Are X and Y Uncorrelated?

1. ê¸°ëŒ€ê°’ ê³„ì‚°:
$$
E[X] = 0*(1/3) + 1*(1/3) + 2*(1/3) = 1
$$
$$
E[Y] = 0*(1/3) + 1*(2/3) = 2/3
$$
1. $E[XY]$ ê³„ì‚°:
$$
E[XY] = 0*1*(1/3) + 1*0*(1/3) + 2*1*(1/3) = 2/3
$$
1. ê³µë¶„ì‚° ê³„ì‚°:
$Cov(X,Y) = E[XY] - E[X]E[Y] = 2/3 - 1*(2/3) = 0$

Xì™€ Yì˜ ê³µë¶„ì‚°ì´ 0ì´ë¯€ë¡œ, Xì™€ YëŠ” ìƒê´€ê´€ê³„ê°€ ì—†ìŠµë‹ˆë‹¤(uncorrelated).

ê²°ë¡ :
(a) Xì™€ YëŠ” ë…ë¦½ì´ ì•„ë‹™ë‹ˆë‹¤.
(b) Xì™€ YëŠ” ìƒê´€ê´€ê³„ê°€ ì—†ìŠµë‹ˆë‹¤(uncorrelated).

## 6. Uncorrelated and Independent Random Variables

(**) Two RVs X and Y are uncorrelated if $Ïƒ_{XY} = 0$. Since $Ïƒ_{XY} = E[XY] - E[X]E[Y]$, the two RVs are uncorrelated if $E[XY] = E[X]E[Y]$. Show that if the RVs are independent, then they are also uncorrelated.

## 7. Covariance and Correlation of Linear Transformation

(***) Let Y = aX + b, where Y and X are RVs and a and b are constants.

(a). Find the covariance of X and Y.

(b). Find the correlation coefficient of X and Y.

## 8. Information Content of Six-Letter English Words
You need to store a six letter English word. Assume there are 26 possible letters to choose from.

(a). Naively (assuming any combination of letters are equally likely and independent) how many bits of information do the 6 letters contain? [compute the shannon entropy of 6 independent RVs, each of which can take one of 26 possible values].

(b). We know that letters are not really independent of each other. What are the implications for how much entropy is really represented by the 6 letters?

(c). We know there are in fact 22,000 6-letter words. Assuming they are equally likely, how many bits of entropy are there in the word?

(d). Some 6-letter words are more common than others - what does that mean for the entropy?

## 9. RFID Bee Monitoring System

(***) An RFID reader and a microcontroller monitor bees entering a bee-hive. Each second it records how many bees have entered. For example:

| Time | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15 | 16 | 17 | 18 | 19 | 20 |
|------|---|---|---|---|---|---|---|---|---|----|----|----|----|----|----|----|----|----|----|----| 
| Bees | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | 0  | 0  | 2  | 0  | 1  | 0  | 0  | 0  | 0  | 1  | 0  |

Currently 2 bits are used each second to store the number of bees (0, 1, 2 or 3), but the microprocessor runs out of storage.

The PMF of the number of bees is: 
$$P(\text{Bee} = b) = \begin{cases}
    15/20, & \text{if } b=0 \\
    4/20,  & \text{if } b=1 \\
    1/20,  & \text{if } b=2 \\
    0,     & \text{if } b \geq 3
\end{cases}$$

(a). Suggest an encoding scheme that can store this more efficiently. [Hint: Remember that you need a way to ensure that the decoder knows where one 'message' ends and the next begins].

(b). After 100 seconds, the original storage scheme uses 200 bits of memory. What is the actual entropy in 100 seconds of observations (in bits)? Assume that individual bee arrival times are independent.

(c). How many bits would your encoding scheme need to store 100 seconds of observations (on average)?

## 10. Lab Room Allocation and Entropy

There is a 10% chance that there won't be enough space in the computer lab, if our module is allocated Lab Room 1 $(P(\text{Full} = \text{true}|\text{Lab} = 1) = 0.1)$; and a 30% if allocated Lab Room 2 $P(\text{Full} = \text{true}|\text{Lab} = 2) = 0.3$. If there is an even chance of being allocated either room;

(a). Compute the (marginal) entropy of the Full random variable, i.e. $H[\text{Full}]$.

(b). Compute the conditional entropy $H[\text{Full}|\text{Lab}]$. Confirm it is no greater than $H[\text{Full}]$.
